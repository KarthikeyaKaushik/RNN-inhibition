{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from keras import optimizers\n",
    "from keras.callbacks import ModelCheckpoint, Callback\n",
    "from keras.layers import Input, Embedding, LSTM, Dense, concatenate, dot, multiply, Lambda\n",
    "from keras.models import Model, Sequential, load_model\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "from keras.utils import to_categorical\n",
    "from keras import backend as K\n",
    "from keras import initializers\n",
    "from random import shuffle\n",
    "import random\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "from pathlib import Path\n",
    "random.seed(999)\n",
    "EMBEDDINGS_PATH = os.path.join(Path(os.getcwd()).parent,'Data\\\\dic_word2vec_ding_new.npy')\n",
    "SENTENCES_PATH = os.path.join(Path(os.getcwd()).parent,'Data\\\\Ding_grammatical.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# power spectra function\n",
    "def power_spectra(w2vec_array, sampling_rate=16):\n",
    "    \"\"\"Computes power spectra using the Discrete Fourier Transform.\n",
    "\n",
    "    Args:\n",
    "        w2vec_array: arrays of shape (n_sentences*time_steps, n_units)\n",
    "            representing hidden layer activations in response to each word of the\n",
    "            concatenated sequence of sentences.\n",
    "        sample_rate: number of measures (outputs of the model) per second.\n",
    "\n",
    "    Returns:\n",
    "        Mean power spectra and frequency axis.\n",
    "    \"\"\"\n",
    "\n",
    "    # Separate each unit and concatenate across words to form 1 vector per unit\n",
    "    unit_vectors = np.transpose(w2vec_array)\n",
    "\n",
    "    # Frequency domain\n",
    "    # num_samples is just the number of data points for each unit\n",
    "    num_samples = unit_vectors.shape[1]\n",
    "    freq = np.fft.rfftfreq(num_samples, d=1./sampling_rate)\n",
    "    print ('freq ' ,freq.shape)\n",
    "    # Calculate the FFT and power spectra for each unit\n",
    "    units_ps = []\n",
    "    for vector in unit_vectors:\n",
    "        ft_unit = np.fft.rfft(vector)  # fft\n",
    "        ps_uni = np.abs(ft_unit) ** 2  # power spectrum\n",
    "        units_ps.append(ps_uni)\n",
    "\n",
    "    # Average power spectra over units\n",
    "    mean_ps = np.mean(units_ps, axis=0)\n",
    "    print ('mean_ps',mean_ps.shape)\n",
    "    return freq, mean_ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(plot_name, freq, power, act,sampling_rate=20,n_samples=60):\n",
    "    \"\"\"Plot all the results of one condition\"\"\"\n",
    "\n",
    "    # Time domain parameters\n",
    "    sampling_interval = 1.0/sampling_rate  # sampling interval\n",
    "    t = np.arange(0, n_samples, sampling_interval)  # time vector\n",
    "    # Build plot\n",
    "    fig, ax = plt.subplots(nrows=2, ncols=1)\n",
    "    ax[0].plot(t, act, linewidth=1.0)\n",
    "    # Axis labels\n",
    "    ax[0].set_xlabel('Time')\n",
    "    ax[0].set_ylabel('Activation')\n",
    "\n",
    "    ax[1].plot(freq[1:], power[1:], 'r', linewidth=1.0)\n",
    "    ax[1].set_xlabel('Freq (Hz)')\n",
    "    ax[1].set_ylabel('Power')\n",
    "\n",
    "    # Adjusts subplot\n",
    "    plt.tight_layout()\n",
    "    # Save\n",
    "    fig.savefig(plot_name+'.pdf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding_masks():\n",
    "    '''\n",
    "    Mask dimensions according to the FY paradigm (without the noise), and get 50 time step representations for each word\n",
    "    '''\n",
    "    random.seed(999)\n",
    "    mask_embeddings = {}\n",
    "    word_embeddings = np.load(EMBEDDINGS_PATH, allow_pickle=True).item()\n",
    "    embedding_dim = word_embeddings['rat'].shape[0]\n",
    "    words_rep = {}\n",
    "    for key in word_embeddings.keys():\n",
    "        word_rep = np.zeros((embedding_dim,50))\n",
    "        mask_embeddings[key] = np.random.uniform(low=40-25,high=40+25,size=(embedding_dim,))\n",
    "        for i in range(50):\n",
    "            mask = (mask_embeddings[key] < (i*5)) * word_embeddings[key]\n",
    "            word_rep[:,i] = mask\n",
    "        words_rep[key] = word_rep\n",
    "    return words_rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_split():\n",
    "    with open(SENTENCES_PATH, 'r') as f:\n",
    "        sentence_list = [row for row in csv.reader(f)]\n",
    "    random.shuffle(sentence_list)\n",
    "    train_sentences = sentence_list[:50]\n",
    "    test_sentences = sentence_list[50:]\n",
    "    return train_sentences, test_sentences\n",
    "\n",
    "train_sentences, test_sentences = get_data_split()    \n",
    "word_representations = get_embedding_masks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input_embeddings(input_data, representations):\n",
    "    '''\n",
    "    Every sentence is sampled at 200 Hz, therefore, every sentence is represented as a 300x(60*200) matrix\n",
    "    '''\n",
    "    random.shuffle(input_data)\n",
    "    input_features = []#np.zeros((representations['rat'].shape[0],len(input_data)*200)) \n",
    "    for sent in input_data:\n",
    "        for word in sent:\n",
    "            input_features.append(representations[word])\n",
    "    # input_features currently has shape - number of sentences(50) * ( 300 * 200 )\n",
    "    input_features = np.concatenate(input_features,axis=1)\n",
    "    # now input_features has shape - 300 * ()\n",
    "    return input_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 10000)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
